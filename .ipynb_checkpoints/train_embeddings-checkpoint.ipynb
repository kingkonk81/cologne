{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import balanced_accuracy_score as bacc\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphnames = ['Cora', 'Citeseer', 'Pubmed']\n",
    "graphname = graphnames[0]\n",
    "emb_size = 10\n",
    "data_dir = os.path.expanduser(\"/home/koki/Desktop/Data/Graphs/\"+graphname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_embsize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwalk_path = os.path.join(data_dir, \"vectors_rwalk_all_\" + str(emb_size) + \".json\")\n",
    "with open(rwalk_path, \"r\") as read_file:\n",
    "    rwalk_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minwise_path = os.path.join(data_dir, \"vectors_minwise_all_\" + str(emb_size) + \".json\")\n",
    "with open(minwise_path, \"r\") as read_file:\n",
    "    minwise_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_path = os.path.join(data_dir, \"vectors_l1_all_\" + str(emb_size) + \".json\")\n",
    "with open(l1_path, \"r\") as read_file:\n",
    "    l1_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(vectors):\n",
    "    pairs = []\n",
    "    cnt = 0\n",
    "    for node, features in vectors.items():\n",
    "        for feature in features:\n",
    "            pairs.append([node, feature[0]])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwalk_pairs = get_pairs(rwalk_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minwise_pairs = get_pairs(minwise_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_pairs = get_pairs(l1_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27080, 27080, 27080)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rwalk_pairs), len(minwise_pairs), len(l1_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['35', '3231'], ['35', '576257'], ['35', '132806']]\n"
     ]
    }
   ],
   "source": [
    "print(rwalk_pairs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_rwalk_exists = os.path.exists(data_dir + \\\n",
    "                            '/w2v_rwalk_emb_'+str(emb_size)+ '_dim_' + str(trained_embsize) +'.model')\n",
    "print(model_rwalk_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_rwalk_exists:\n",
    "    model_rwalk = Word2Vec.load(data_dir + \\\n",
    "                            '/w2v_rwalk_emb_'+str(emb_size)+ '_dim_' + str(trained_embsize) + '.model')\n",
    "else:\n",
    "    model_rwalk = Word2Vec(\n",
    "                rwalk_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                #negative=1,\n",
    "                iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_rwalk_exists:\n",
    "    model_rwalk.save(data_dir + '/w2v_rwalk_emb_'+str(emb_size)+'_dim_' + str(trained_embsize) +'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_minwise_exists = os.path.exists(data_dir + \\\n",
    "                            '/w2v_minwise_emb_'+str(emb_size)+ '_dim_' + str(trained_embsize) + '.model')\n",
    "print(model_minwise_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_minwise_exists:\n",
    "    model_minwise = Word2Vec.load(data_dir + \\\n",
    "                                  '/w2v_minwise_emb_'+str(emb_size)+'_dim_' + str(trained_embsize) + '.model')\n",
    "else:\n",
    "    model_minwise = Word2Vec(\n",
    "                minwise_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                #negative=2,\n",
    "                iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_minwise_exists:\n",
    "    model_minwise.save(data_dir + '/w2v_minwise_emb_'+str(emb_size)+ '_dim_' + str(trained_embsize) + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_l1_exists = os.path.exists(data_dir + \\\n",
    "                                 '/w2v_l1_emb_'+str(emb_size)+ '_dim_' + str(trained_embsize) + '.model')\n",
    "print(model_l1_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_l1_exists:\n",
    "    model_l1 = Word2Vec.load(data_dir + '/w2v_l1_emb_'+str(emb_size)+'_dim_' + str(trained_embsize)+'.model')\n",
    "else:\n",
    "    model_l1 = Word2Vec(\n",
    "                minwise_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                #negative=2,\n",
    "                iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_l1_exists:\n",
    "    model_l1.save(data_dir + '/w2v_l1_emb_'+str(emb_size)+'_dim_' + str(trained_embsize)+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_labels = pd.read_csv(data_dir + '/nodes_with_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(model, nodes_with_labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    for idx, row in nodes_with_labels.iterrows():\n",
    "        X.append([float(x) for x in model[str(row['node'])]])\n",
    "        if row['label'] not in labels:\n",
    "            labels[row['label']] = len(labels)\n",
    "        y.append(labels[row['label']])\n",
    "    X = np.array(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_rw, y_rw = get_X_y(model_rwalk, nodes_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_mw, y_mw = get_X_y(model_minwise, nodes_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_l1, y_l1 = get_X_y(model_l1, nodes_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_bacc(X, y, nr_iters):\n",
    "    lgb_params = {'objective':'multiclass',\n",
    "                  'metric': 'multi_error',\n",
    "            'boosting_type':'gbdt',\n",
    "            'n_jobs':4,\n",
    "            'max_depth':-1,\n",
    "             'num_class': len(set(y)),\n",
    "            'learning_rate':0.1,\n",
    "            'tree_learner':'serial',\n",
    "            'n_estimators':2000,\n",
    "            'verbose':-1,\n",
    "            'seed': 73,\n",
    "            'feature_fraction':1,\n",
    "            'badding_seed' : 1}\n",
    "    accs = []    \n",
    "    for i in range(nr_iters):\n",
    "        print('Iter', i)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)\n",
    "        clf = lgb.LGBMClassifier( **lgb_params) \n",
    "        X_train_clf, X_test, y_train_clf, y_test =  train_test_split(X_train, y_train)\n",
    "        clf.fit(X_train_clf, y_train_clf, eval_set=[(X_train_clf, y_train_clf), (X_test, y_test)], \n",
    "                    early_stopping_rounds=50, verbose=100)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        acc = bacc(y_pred, y_val)\n",
    "        accs.append(acc)\n",
    "        print('Balanced accuracy score', acc)\n",
    "    mean = 100.0*np.round(np.mean(accs), 3)\n",
    "    std = 100.0*np.round(np.std(accs), 3)\n",
    "    print(\"{}\\% $\\pm$ {}\\%\".format(np.round(mean, 1), np.round(std, 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.278598\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.263838\n",
      "Balanced accuracy score 0.78211801098798\n",
      "Iter 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.247232\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.232472\n",
      "[300]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.221402\n",
      "Early stopping, best iteration is:\n",
      "[331]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.215867\n",
      "Balanced accuracy score 0.7738339783784277\n",
      "Iter 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.225092\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.217712\n",
      "Balanced accuracy score 0.7981901925613242\n",
      "Iter 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.212177\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.204797\n",
      "Early stopping, best iteration is:\n",
      "[164]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.201107\n",
      "Balanced accuracy score 0.7783574762833949\n",
      "Iter 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.258303\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.243542\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.238007\n",
      "Balanced accuracy score 0.7699800027864571\n",
      "Iter 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.232472\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.223247\n",
      "Balanced accuracy score 0.7582064808398716\n",
      "Iter 6\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.273063\n",
      "Balanced accuracy score 0.7769713050143138\n",
      "Iter 7\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.238007\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.223247\n",
      "Balanced accuracy score 0.7885997652922\n",
      "Iter 8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.225092\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.221402\n",
      "Balanced accuracy score 0.8171299553806376\n",
      "Iter 9\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.243542\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.234317\n",
      "Balanced accuracy score 0.7528554611151479\n",
      "78.0\\% $\\pm$ 1.8\\%\n"
     ]
    }
   ],
   "source": [
    "get_mean_bacc(X_rw, y_rw, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.202952\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.195572\n",
      "Balanced accuracy score 0.7968610104875262\n",
      "Iter 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.197417\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.182657\n",
      "Early stopping, best iteration is:\n",
      "[213]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.178967\n",
      "Balanced accuracy score 0.7999360323828035\n",
      "Iter 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.221402\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.214022\n",
      "Balanced accuracy score 0.7877491097508839\n",
      "Iter 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.214022\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.208487\n",
      "Balanced accuracy score 0.8067082030847846\n",
      "Iter 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.191882\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.186347\n",
      "Balanced accuracy score 0.7992611197534066\n",
      "Iter 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.184502\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.180812\n",
      "Balanced accuracy score 0.7941165211522258\n",
      "Iter 6\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.182657\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.175277\n",
      "Balanced accuracy score 0.7889622807867214\n",
      "Iter 7\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.202952\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.195572\n",
      "Balanced accuracy score 0.8173497161302743\n",
      "Iter 8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.230627\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.221402\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.215867\n",
      "Balanced accuracy score 0.8011560832484014\n",
      "Iter 9\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.190037\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.178967\n",
      "Balanced accuracy score 0.7839137748575575\n",
      "79.8\\% $\\pm$ 0.9\\%\n"
     ]
    }
   ],
   "source": [
    "get_mean_bacc(X_mw, y_mw, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.208487\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.195572\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.193727\n",
      "Balanced accuracy score 0.823056358385177\n",
      "Iter 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.206642\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.193727\n",
      "Balanced accuracy score 0.8314301579985722\n",
      "Iter 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.191882\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.182657\n",
      "Balanced accuracy score 0.8166035008150239\n",
      "Iter 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.206642\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.201107\n",
      "Balanced accuracy score 0.8001203996112105\n",
      "Iter 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.186347\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.177122\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.171587\n",
      "Balanced accuracy score 0.794370268900889\n",
      "Iter 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.169742\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.162362\n",
      "Balanced accuracy score 0.792600767756747\n",
      "Iter 6\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.214022\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.212177\n",
      "Early stopping, best iteration is:\n",
      "[157]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.204797\n",
      "Balanced accuracy score 0.8076284379963099\n",
      "Iter 7\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.221402\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.217712\n",
      "Balanced accuracy score 0.8326404678329695\n",
      "Iter 8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.206642\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.190037\n",
      "Balanced accuracy score 0.8346986641873507\n",
      "Iter 9\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.206642\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.202952\n",
      "Balanced accuracy score 0.7852857473066532\n",
      "81.2\\% $\\pm$ 1.7\\%\n"
     ]
    }
   ],
   "source": [
    "get_mean_bacc(X_l1, y_l1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54943544, -0.03144258,  0.1593027 ,  0.34443098,  0.62527102,\n",
       "        1.39308059,  0.50897878,  0.18592592, -0.26989779,  0.62045872,\n",
       "        0.77887779, -0.49794203,  0.67839801, -0.60232335,  0.21792775,\n",
       "       -0.67680496, -0.65120906,  0.18713106, -0.42362121, -0.93551505,\n",
       "       -0.74547589,  0.27052885,  0.97278225, -0.4303042 , -0.55773205,\n",
       "       -0.35216695, -0.24470426, -0.1260681 ,  0.34674758, -0.00248211,\n",
       "       -0.25157702, -0.13554797, -0.87472546,  0.32508022, -0.04656049,\n",
       "       -0.12327956, -0.89316028, -1.1099757 ,  0.05556352, -0.02967277,\n",
       "        0.64539856,  1.2539674 , -0.9514541 ,  0.07091854,  0.10108402,\n",
       "        0.03459425,  0.37477243, -0.33428699, -0.57108504, -0.77540177])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 818, 1: 180, 2: 217, 3: 426, 4: 351, 5: 418, 6: 298}),\n",
       " Counter({0: 818, 1: 180, 2: 217, 3: 426, 4: 351, 5: 418, 6: 298}))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_l1), Counter(y_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitd5d6c22048554957af993f0c6b0a4eef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
