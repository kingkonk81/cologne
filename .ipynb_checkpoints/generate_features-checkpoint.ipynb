{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from BinaryStream import BinaryStream\n",
    "from TabulationHashing import TabulationHashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphnames = ['Cora', 'Citeseer', 'Pubmed']\n",
    "graphname = graphnames[0]\n",
    "emb_size = 50\n",
    "data_dir = os.path.expanduser(\"Graphs/\"+graphname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "randompath = \"random/bits.01\"\n",
    "rand_gen = TabulationHashing(randompath, rows=4, shift=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodedata_path = data_dir + \"/data/nodedata.json\" #os.path.join(data_dir, \"nodedata.json\")\n",
    "with open(nodedata_path, \"r\") as read_file:\n",
    "    nodedata = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label=Neural_Networks',\n",
       " {'w-118': 1,\n",
       "  'w-171': 1,\n",
       "  'w-533': 1,\n",
       "  'w-820': 1,\n",
       "  'w-1209': 1,\n",
       "  'w-1241': 1,\n",
       "  'w-1273': 1}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nodedata[list(nodedata.keys())[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph_from_edge_list(filename, nodedata):\n",
    "    G = nx.Graph()\n",
    "    path = data_dir + \"/data/\" + filename\n",
    "    with open(path, 'r') as edgefile: # os.path.join(data_dir, filename),\n",
    "        for line in edgefile:\n",
    "            line_split = line.split(':')\n",
    "            if len(line_split) > 1:\n",
    "                l0 = line_split[0]\n",
    "                l1 = line_split[1]\n",
    "                u = l0.strip()\n",
    "                v = l1.strip()\n",
    "                if u in nodedata and v in nodedata:\n",
    "                    G.add_edge(u, v)\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = read_graph_from_edge_list(\"all_graph_edges.txt\", nodedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 5278)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = read_graph_from_edge_list(\"graph_edges_reduced.txt\", nodedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 4222)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.number_of_nodes(), H.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = read_graph_from_edge_list(\"removed_edges.txt\", nodedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1281, 1056)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.number_of_nodes(), R.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random int in [start, end]\n",
    "def get_rnd_int_in_range(rand_gen, start, end):\n",
    "    r = random.randint(0, 1e10)\n",
    "    diff = end - start + 1\n",
    "    rval = rand_gen.hashValueInt(r)%diff\n",
    "    return rval+start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rnd_int_in_range(rand_gen, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnd_value(rand_gen, min_val):\n",
    "    rval = 0\n",
    "    while rval < min_val:\n",
    "        r = random.randint(0, 1e10)\n",
    "        rval = rand_gen.hashValue(r)\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25111363822251553"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rnd_value(rand_gen, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G, node, depth, features, rand_gen):\n",
    "    node = str(node)\n",
    "    cnt = 0\n",
    "    curr_node = node\n",
    "    while cnt < depth and G.degree[curr_node] > 0:\n",
    "        nbrs = [nbr for nbr in G.neighbors(curr_node)]\n",
    "        curr_node = nbrs[get_rnd_int_in_range(rand_gen, 0, len(nbrs)-1)]\n",
    "        cnt += 1\n",
    "    subject, features_node = features[curr_node]\n",
    "    w = random.choices(population=list(features_node.keys()), weights=list(features_node.values()), k=1)[0]\n",
    "    return curr_node, subject, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('87417', 'label=Genetic_Algorithms', 'w-250')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = list(H.nodes())[20]\n",
    "random_walk(H, node, 2, features=nodedata, rand_gen=rand_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_nodes_random_walk(G, depth, nr_walks, features, rand_gen):\n",
    "    vectors = {}\n",
    "    for node in G.nodes():\n",
    "        vectors[node] = [None for _ in range(nr_walks)]\n",
    "        for walk in range(nr_walks):\n",
    "            sample, subject, feature = random_walk(G, node, depth, features, rand_gen)\n",
    "            vectors[node][walk] = (sample, subject, feature)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time RW 2.049431800842285\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "vectors_rw_all = all_nodes_random_walk(G, 2, emb_size, features=nodedata, rand_gen=rand_gen)\n",
    "end = time.time()\n",
    "print('Elapsed time RW', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_rw_reduced = all_nodes_random_walk(H, 2, emb_size, features=nodedata, rand_gen=rand_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('575292', 'label=Genetic_Algorithms', 'w-1198'),\n",
       " ('262178', 'label=Genetic_Algorithms', 'w-333'),\n",
       " ('427606', 'label=Genetic_Algorithms', 'w-464')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_rw_all[list(vectors_rw_all.keys())[100]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = data_dir + \"/vectors/vectors_rwalk_all_\" + str(emb_size) + \".json\"\n",
    "#os.path.join(data_dir, \"vectors_rwalk_all_\" + str(emb_size) + \".json\")\n",
    "with open(jsonpath, 'w') as outfile:\n",
    "    json.dump(vectors_rw_all, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = data_dir + \"/vectors/vectors_rwalk_reduced_\" + str(emb_size) + \".json\"\n",
    "# os.path.join(data_dir, \"vectors_rwalk_reduced_\" + str(emb_size) + \".json\")\n",
    "with open(jsonpath, 'w') as outfile:\n",
    "    json.dump(vectors_rw_reduced, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minwise_iterate(G, rnd_nodes, nr_iter, features):\n",
    "    node_labels = [{} for _ in range(nr_iter+1)]\n",
    "    if nr_iter < 1:\n",
    "        raise Exception(\"There must be at least one iteration\")\n",
    "    node_labels[0] = rnd_nodes\n",
    "    for iter in range(nr_iter):\n",
    "        rnd_nodes_iter = node_labels[iter]\n",
    "        print('Iteration', iter)\n",
    "        for u in G.nodes():\n",
    "            w_u = rnd_nodes_iter[u]\n",
    "            for v in G.neighbors(u):\n",
    "                w_u = min(rnd_nodes_iter[v], w_u)\n",
    "            node_labels[iter+1][u] = w_u\n",
    "    return node_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(d, k, rand_gen, min_val):\n",
    "    if k not in d:\n",
    "        d[k] = get_rnd_value(rand_gen, min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random numbers for nodes and features for each embedding \n",
    "def init_dicts(nodedata, emb_size, rand_gen=rand_gen):\n",
    "    min_val = 1e-6\n",
    "    nodes_rnd = [{} for _ in range(emb_size)]\n",
    "    labels_rnd = [{} for _ in range(emb_size)]\n",
    "    feats_rnd = [{} for _ in range(emb_size)]\n",
    "    for i in range(emb_size):\n",
    "        nodes_rnd_i = nodes_rnd[i]\n",
    "        labels_rnd_i = labels_rnd[i]\n",
    "        feats_rnd_i = feats_rnd[i]\n",
    "        for node, feats in nodedata.items():\n",
    "            update_dict(nodes_rnd_i, node, rand_gen, min_val)\n",
    "            update_dict(labels_rnd_i, feats[0], rand_gen, min_val)\n",
    "            for f, weight_f in feats[1].items():\n",
    "                update_dict(feats_rnd_i, f, rand_gen, min_val)\n",
    "    return nodes_rnd, labels_rnd, feats_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_rnd, labels_rnd, feats_rnd = init_dicts(nodedata, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label=Neural_Networks': 0.5744633343192777, 'label=Rule_Learning': 0.23460164579904508, 'label=Reinforcement_Learning': 0.20869038102312337, 'label=Probabilistic_Methods': 0.7762539606541157, 'label=Theory': 0.8341305829247562, 'label=Genetic_Algorithms': 0.41657855166284, 'label=Case_Based': 0.007728665922007075}, {'label=Neural_Networks': 0.5307272817214225, 'label=Rule_Learning': 0.8372250791511366, 'label=Reinforcement_Learning': 0.10686022834511369, 'label=Probabilistic_Methods': 0.3498957911309028, 'label=Theory': 0.7839438127140653, 'label=Genetic_Algorithms': 0.5477515560814709, 'label=Case_Based': 0.2032043860703288}]\n"
     ]
    }
   ],
   "source": [
    "# print(labels_rnd[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minwise_samples(G, nodedata, feats_rnd, nr_iter, emb_size):\n",
    "    node_labels = [{} for _ in range(emb_size)]\n",
    "    for i in range(emb_size):\n",
    "        node_labels_i = node_labels[i]\n",
    "        feats_rnd_i = feats_rnd[i]\n",
    "        for node, feats in nodedata.items():\n",
    "            min_feature_value = 1e3\n",
    "            min_feature = None\n",
    "            for f in feats[1]:\n",
    "                if feats_rnd_i[f] < min_feature_value:\n",
    "                    min_feature = f\n",
    "                    min_feature_value = feats_rnd_i[f]\n",
    "            node_labels_i[node] = (min_feature_value, node, feats[0], min_feature)\n",
    "            \n",
    "    node_labels_all = [[{} for _ in range(emb_size)] for _ in range(nr_iter+1)]\n",
    "    node_labels_all[0] = node_labels\n",
    "    for i in range(nr_iter):\n",
    "        node_labels_iter = node_labels_all[i]\n",
    "        print('Iteration', i)\n",
    "        for u in G.nodes():\n",
    "            for t in range(emb_size):\n",
    "                w_u = node_labels_iter[t][u]\n",
    "                for v in G.neighbors(u):\n",
    "                        w_u = min(node_labels_iter[t][v], w_u)\n",
    "                node_labels_all[i+1][t][u] = w_u\n",
    "            \n",
    "    node_embeddings = {n:[] for n in G.nodes()}\n",
    "    for u in G.nodes():\n",
    "        for nl in node_labels_all[nr_iter]:\n",
    "            node_embeddings[u].append((nl[u][1], nl[u][2], nl[u][3]))\n",
    "    return node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Elapsed time MW 0.7884116172790527\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "nodes_rnd, labels_rnd, feats_rnd = init_dicts(nodedata, emb_size)\n",
    "vectors_mw_all = generate_minwise_samples(G, nodedata, feats_rnd, nr_iter=2, emb_size=emb_size)\n",
    "end = time.time()\n",
    "print('Elapsed time MW', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = data_dir + \"/vectors/vectors_minwise_all_\" + str(emb_size) + \".json\"\n",
    "#os.path.join(data_dir, \"vectors_minwise_all_\" + str(emb_size) + \".json\")\n",
    "with open(jsonpath, 'w') as outfile:\n",
    "    json.dump(vectors_mw_all, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n"
     ]
    }
   ],
   "source": [
    "vectors_mw_reduced = generate_minwise_samples(H, nodedata, feats_rnd, nr_iter=2, emb_size=emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = data_dir + \"/vectors/vectors_minwise_reduced_\" + str(emb_size) + \".json\"\n",
    "# os.path.join(data_dir, \"vectors_minwise_reduced_\" + str(emb_size) + \".json\")\n",
    "with open(jsonpath, 'w') as outfile:\n",
    "    json.dump(vectors_mw_reduced, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_L1_samples(G, nodedata, rand_gen, nr_iter, emb_size, top):\n",
    "    sketches = [[{} for _ in range(emb_size)] for _ in range(nr_iter+1)]\n",
    "    \n",
    "    min_val = 1e-6\n",
    "    cnt = 0\n",
    "    for u, (subject, features) in nodedata.items():\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print('nodes processed', cnt)\n",
    "        for i in range(emb_size):\n",
    "            sketches[0][i][u] = {}\n",
    "            max_w = 0\n",
    "            max_f = None\n",
    "            for f, w_f in features.items():\n",
    "                w_rnd = w_f/get_rnd_value(rand_gen, min_val) #random.random()\n",
    "                if w_rnd > max_w:\n",
    "                    max_w = w_rnd\n",
    "                    max_f = f\n",
    "            if max_w > 0:\n",
    "                sketches[0][i][u] = {u : (max_w, max_f)}\n",
    "            #print(max_f, max_w)\n",
    "    \n",
    "    for iter in range(nr_iter):\n",
    "        print('ITERATION', iter)\n",
    "        for emb in range(emb_size):\n",
    "            # print('emb', emb)\n",
    "            sketch_iter_emb = copy.deepcopy(sketches[iter][emb])\n",
    "            # print(len(sketch_iter_emb))\n",
    "            new_sketches = {}\n",
    "            for u in G.nodes():\n",
    "                if u not in sketch_iter_emb:\n",
    "                    continue\n",
    "                sketch_u = copy.deepcopy(sketch_iter_emb[u])\n",
    "                for v in G.neighbors(u):\n",
    "                    sketch_v = sketch_iter_emb[v]\n",
    "                    for t, (w_f, f) in sketch_v.items():\n",
    "                        sketch_u.setdefault(t, (0, None))\n",
    "                        weight = sketch_u[t][0] + w_f\n",
    "                        sketch_u[t] = (weight, f)\n",
    "                triples = []\n",
    "                for node, feat_node in sketch_u.items():\n",
    "                    triples.append((feat_node[0], feat_node[1], node))\n",
    "                top_triples = sorted(triples, reverse=True)[:top]\n",
    "                #print(top_triples)\n",
    "                new_sketches[u] = {tr[2] : (tr[0], tr[1]) for tr in top_triples}\n",
    "            sketches[iter+1][emb] = new_sketches\n",
    "    return sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "randompath = \"random/bits.01\"\n",
    "rand_gen = TabulationHashing(randompath, rows=4, shift=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes processed 1000\n",
      "nodes processed 2000\n",
      "ITERATION 0\n",
      "ITERATION 1\n",
      "Elapsed time L1 18.305689811706543\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sketches_l1_all = generate_L1_samples(G, nodedata, rand_gen, nr_iter=2, emb_size=emb_size, top=10)\n",
    "end = time.time()\n",
    "print('Elapsed time L1', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes processed 1000\n",
      "nodes processed 2000\n",
      "ITERATION 0\n",
      "ITERATION 1\n"
     ]
    }
   ],
   "source": [
    "sketches_l1_reduced = generate_L1_samples(H, nodedata, rand_gen, nr_iter=2, emb_size=emb_size, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sketches_l1_all[2]), len(sketches_l1_reduced[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_l1(nodedata, sketches):\n",
    "    embeddings = {}\n",
    "    for node in nodedata.keys():\n",
    "        embeddings[node] = []\n",
    "    for e in range(emb_size):\n",
    "        for node, d in sketches[2][e].items():\n",
    "            max_word = None\n",
    "            max_weight = 0\n",
    "            for sampled_node, ww in d.items(): # ww: weight word\n",
    "                if ww[0] > max_weight:\n",
    "                    max_word = ww[1]\n",
    "                    max_weight = ww[0]\n",
    "            label = nodedata[node][0]\n",
    "            if max_weight > 0:\n",
    "                embeddings[node].append((sampled_node, label, max_word))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_l1_all = get_embeddings_l1(nodedata, sketches_l1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_l1_reduced = get_embeddings_l1(nodedata, sketches_l1_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = data_dir + \"/vectors/vectors_l1_all_\" + str(emb_size) + \".json\"\n",
    "# os.path.join(data_dir, \"vectors_l1_all_\" + str(emb_size) + \".json\")\n",
    "with open(jsonpath, 'w') as outfile:\n",
    "    json.dump(vectors_l1_all, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = data_dir + \"/vectors/vectors_l1_reduced_\" + str(emb_size) + \".json\"\n",
    "#os.path.join(data_dir, \"vectors_l1_reduced_\" + str(emb_size) + \".json\")\n",
    "with open(jsonpath, 'w') as outfile:\n",
    "    json.dump(vectors_l1_reduced, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
