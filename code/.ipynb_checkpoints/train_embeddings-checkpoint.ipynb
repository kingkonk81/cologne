{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training continuous embeddings \n",
    "We use the generated samples to train embeddings using word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import balanced_accuracy_score as bacc\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Graphs/Wikipedia\n"
     ]
    }
   ],
   "source": [
    "graphnames = ['Cora', 'Citeseer', 'Pubmed', 'HomoSapiens', 'BlogCatalog', 'Wikipedia']\n",
    "idx = 5\n",
    "graphname = graphnames[idx]\n",
    "multilabel=False\n",
    "if idx > 2:\n",
    "    multilabel=True\n",
    "emb_size = 10\n",
    "hop = 4\n",
    "data_dir = os.path.expanduser(\"../Graphs/\"+graphname)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_embsize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwalk_path = data_dir + \"/vectors/vectors_rwalk_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(rwalk_path, \"r\") as read_file:\n",
    "    rwalk_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesketch_path = data_dir + \"/vectors/vectors_nodesketch_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(nodesketch_path, \"r\") as read_file:\n",
    "    ns_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minwise_path = data_dir + \"/vectors/vectors_minwise_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(minwise_path, \"r\") as read_file:\n",
    "    minwise_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(minwise_vectors.keys())[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3448', 'label=0=', '3448'],\n",
       " ['407', 'label=0=8=', '407'],\n",
       " ['4', 'label=9=', '4'],\n",
       " ['107', 'label=0=14=19=', '107'],\n",
       " ['294', 'label=0=7=', '294'],\n",
       " ['413', 'label=7=12=', '413'],\n",
       " ['554', 'label=0=', '554'],\n",
       " ['137', 'label=0=14=19=', '137'],\n",
       " ['6', 'label=13=', '6'],\n",
       " ['1471', 'label=7=', '1471']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwalk_vectors[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1313', 'label=0=', '1313'],\n",
       " ['4370', 'label=7=', '4370'],\n",
       " ['1674', 'label=0=', '1674'],\n",
       " ['2600', 'label=6=', '2600'],\n",
       " ['3783', 'label=0=', '3783'],\n",
       " ['2851', 'label=0=8=', '2851'],\n",
       " ['1963', 'label=5=8=', '1963'],\n",
       " ['3358', 'label=0=', '3358'],\n",
       " ['4482', 'label=6=', '4482'],\n",
       " ['2102', 'label=0=14=', '2102']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minwise_vectors[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_path = data_dir + \"/vectors/vectors_l1_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(l1_path, \"r\") as read_file:\n",
    "    l1_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_path = data_dir + \"/vectors/vectors_l2_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(l2_path, \"r\") as read_file:\n",
    "    l2_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(vectors):\n",
    "    pairs = []\n",
    "    cnt = 0\n",
    "    for node, features in vectors.items():\n",
    "        for feature in features:\n",
    "            pairs.append([node, feature[0]])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwalk_pairs = get_pairs(rwalk_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_pairs = get_pairs(ns_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "minwise_pairs = get_pairs(minwise_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_pairs = get_pairs(l1_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_pairs = get_pairs(l2_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47770, 47770, 47770, 47770, 47770)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rwalk_pairs), len(ns_pairs), len(minwise_pairs), len(l1_pairs), len(l2_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '4'], ['0', '25'], ['0', '0'], ['0', '2927'], ['0', '1768'], ['0', '111'], ['0', '103'], ['0', '54'], ['0', '19'], ['0', '4']]\n"
     ]
    }
   ],
   "source": [
    "print(rwalk_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_rwalk_path = data_dir + '/w2v/w2v_rwalk_emb_'+str(emb_size)+'_hop_' + str(hop) + \\\n",
    "                '_dim_' + str(trained_embsize) +'.model'\n",
    "model_rwalk_exists = os.path.exists(model_rwalk_path)\n",
    "print(model_rwalk_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_rwalk_exists:\n",
    "    model_rwalk = Word2Vec.load(model_rwalk_path)\n",
    "else:\n",
    "    model_rwalk = Word2Vec(\n",
    "                rwalk_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_rwalk_exists:\n",
    "    model_rwalk.save(model_rwalk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_ns_path = data_dir + '/w2v/w2v_ns_emb_'+str(emb_size)+'_hop_' + str(hop) + \\\n",
    "        '_dim_' + str(trained_embsize) +'.model'\n",
    "model_ns_exists = os.path.exists(model_ns_path)\n",
    "print(model_ns_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_ns_exists:\n",
    "    model_ns = Word2Vec.load(model_ns_path)\n",
    "else:\n",
    "    model_ns = Word2Vec(\n",
    "                ns_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                iter=300)\n",
    "    model_ns.save(model_ns_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_minwise_path = data_dir + '/w2v/w2v_minwise_emb_'+str(emb_size)+'_hop_' + str(hop) + \\\n",
    "        '_dim_' + str(trained_embsize) +'.model'\n",
    "model_minwise_exists = os.path.exists(model_minwise_path)\n",
    "print(model_minwise_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_minwise_exists:\n",
    "    model_minwise = Word2Vec.load(model_minwise_path)\n",
    "else:\n",
    "    model_minwise = Word2Vec(\n",
    "                minwise_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                iter=300)\n",
    "    model_minwise.save(model_minwise_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_l1_path = data_dir + '/w2v/w2v_l1_emb_'+str(emb_size)+'_hop_' + str(hop) + \\\n",
    "        '_dim_' + str(trained_embsize) +'.model'\n",
    "model_l1_exists = os.path.exists(model_l1_path)\n",
    "print(model_l1_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_l1_exists:\n",
    "    model_l1 = Word2Vec.load(model_l1_path)\n",
    "else:\n",
    "    model_l1 = Word2Vec(\n",
    "                l1_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                #negative=2,\n",
    "                iter=300)\n",
    "    model_l1.save(model_l1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_l2_path = data_dir + '/w2v/w2v_l2_emb_'+str(emb_size)+'_hop_' + str(hop) + \\\n",
    "        '_dim_' + str(trained_embsize) +'.model'\n",
    "model_l2_exists = os.path.exists(model_l2_path)\n",
    "print(model_l2_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_l2_exists:\n",
    "    model_l2 = Word2Vec.load(model_l2_path)\n",
    "else:\n",
    "    model_l2 = Word2Vec(\n",
    "                l2_pairs, \n",
    "                size=trained_embsize, \n",
    "                window=2, \n",
    "                min_count=0, \n",
    "                sg=1, \n",
    "                workers=4, \n",
    "                #negative=2,\n",
    "                iter=300)\n",
    "    model_l2.save(model_l2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_labels = pd.read_csv(data_dir + '/data/nodes_with_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>label=3=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>label=16=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>label=11=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>label=2=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>label=9=</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node      label\n",
       "0     0   label=3=\n",
       "1     1  label=16=\n",
       "2     2  label=11=\n",
       "3     3   label=2=\n",
       "4     4   label=9="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_with_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dataset with labels from the trained embeddings\n",
    "def get_X_y(model, nodes_with_labels, multilabel=False):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    for idx, row in nodes_with_labels.iterrows():\n",
    "        \n",
    "        X.append([float(x) for x in model[str(row['node'])]])\n",
    "        row_labels = [row['label']]\n",
    "        if multilabel:\n",
    "            row_labels = row[\"label\"].split(\"=\")\n",
    "            row_labels = row_labels[1:-1]   \n",
    "        for rl in row_labels:\n",
    "            if rl not in labels:\n",
    "                labels[rl] = len(labels)\n",
    "        enc_label = []\n",
    "        for rl in row_labels:\n",
    "            enc_label.append(labels[rl])\n",
    "        y.append(enc_label)\n",
    "    X = np.array(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X_rw, y_rw = get_X_y(model_rwalk, nodes_with_labels, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X_ns, y_ns = get_X_y(model_ns, nodes_with_labels, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X_mw, y_mw = get_X_y(model_minwise, nodes_with_labels, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X_l1, y_l1 = get_X_y(model_l1, nodes_with_labels, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X_l2, y_l2 = get_X_y(model_l2, nodes_with_labels, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4777, 50), (4777, 50), (4777, 50), (4777, 50), (4777, 50))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rw.shape, X_ns.shape, X_mw.shape, X_l1.shape, X_l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [2], [3], [4]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_l1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_distribution(y):\n",
    "    counts = {}\n",
    "    for labels_i in y:\n",
    "        for l_i in labels_i:\n",
    "            counts.setdefault(l_i, 0)\n",
    "            counts[l_i] += 1\n",
    "    \n",
    "    top_counts = sorted([(cnt, lbl) for lbl, cnt in counts.items()], reverse=True)\n",
    "    plt.bar([i for i in range(len(top_counts))], [c for c, _ in top_counts], alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_label_distribution(y_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, top=10):\n",
    "    \n",
    "    counts = {}\n",
    "    for labels_i in y:\n",
    "        for l_i in labels_i:\n",
    "            counts.setdefault(l_i, 0)\n",
    "            counts[l_i] += 1\n",
    "    \n",
    "    top_counts = sorted([(cnt, lbl) for lbl, cnt in counts.items()], reverse=True)[:top]\n",
    "    labels = {cnt_lbl[1]: i for i,cnt_lbl in enumerate(top_counts)}\n",
    "    \n",
    "    top = min(top, len(counts)-1)\n",
    "    \n",
    "#     labels = {}\n",
    "#     for labels_i in y:\n",
    "#         for l_i in labels_i:\n",
    "#             labels.setdefault(l_i, len(labels))\n",
    "    encoded = np.zeros((len(y), top+1))\n",
    "    for i, labels_i in enumerate(y):\n",
    "        for l_i in labels_i:\n",
    "            if l_i in labels:\n",
    "                encoded[i, labels[l_i]] = 1\n",
    "            else:\n",
    "                encoded[i, top] = 1\n",
    "            \n",
    "    return encoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4777, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(y_rw, top=10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(X, y, nr_iters):\n",
    "    labels = set()\n",
    "    for labels_i in y:\n",
    "        for l_i in labels_i:\n",
    "            labels.add(l_i)\n",
    "    lgb_params = {'objective':'multiclass',\n",
    "                  'metric': 'multi_logloss',\n",
    "            'boosting_type':'gbdt',\n",
    "            'n_jobs':4,\n",
    "            'max_depth':-1,\n",
    "             'num_class': len(labels),\n",
    "            'learning_rate':0.1,\n",
    "            'tree_learner':'serial',\n",
    "            'n_estimators':2000,\n",
    "            'verbose':-1,\n",
    "            'seed': 73,\n",
    "            'feature_fraction':1}\n",
    "    micros = []\n",
    "    macros = []\n",
    "    for i in range(nr_iters):\n",
    "        print('Iter', i)\n",
    "        y = MultiLabelBinarizer().fit_transform(y)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)\n",
    "        clf = lgb.LGBMClassifier( **lgb_params) \n",
    "        clf = OneVsRestClassifier(clf)\n",
    "        X_train_clf, X_test, y_train_clf, y_test =  train_test_split(X_train, y_train)\n",
    "        \n",
    "        clf.fit(X_train_clf, y_train_clf)#, eval_set=[(X_train_clf, y_train_clf), (X_test, y_test)], \n",
    "                        # early_stopping_rounds=50, verbose=100)\n",
    "        y_pred_prob = clf.predict_proba(X_val)\n",
    "        y_val_mat = one_hot(y_val)\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        n_classes = y_val_mat.shape[1]\n",
    "        y_test_mat = one_hot(y_test)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_val_mat[:, i], y_pred_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_val_mat.ravel(), y_pred_prob.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        print('Micro AUC', roc_auc[\"micro\"])\n",
    "        print('Macro AUC', roc_auc[\"macro\"])\n",
    "        micros.append(roc_auc[\"micro\"])\n",
    "        macros.append(roc_auc[\"macro\"])\n",
    "    mean_micro = 100.0*np.round(np.mean(micros), 3)\n",
    "    mean_macro = 100.0*np.round(np.mean(macros), 3)\n",
    "    std_micro = 100.0*np.round(np.std(micros), 3)\n",
    "    std_macro = 100.0*np.round(np.std(macros), 3)\n",
    "    print(\"{} $\\pm$ {} & {} $\\pm$ {}\".format(np.round(mean_micro, 3), np.round(std_micro, 3),\\\n",
    "                                             np.round(mean_macro, 3), np.round(std_macro, 3)))\n",
    "    \n",
    "    \n",
    "#     # Plot all ROC curves\n",
    "#     plt.figure()\n",
    "#     plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#              label='micro-average ROC curve (area = {0:0.3f})'\n",
    "#                    ''.format(roc_auc[\"micro\"]),\n",
    "#              color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "#     plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "#              label='macro-average ROC curve (area = {0:0.3f})'\n",
    "#                    ''.format(roc_auc[\"macro\"]),\n",
    "#              color='navy', linestyle=':', linewidth=4)\n",
    "    \n",
    "# #     plt.figure()\n",
    "#     lw = 2\n",
    "# #     plt.plot(fpr[2], tpr[2], color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "#     plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('Receiver operating characteristic example')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_classification(X, y, top_classes, res_path):\n",
    "    # mlb = MultiLabelBinarizer()\n",
    "    y = one_hot(y, top_classes) # mlb.fit_transform(y)\n",
    "    \n",
    "#     accs = []\n",
    "#     micros = []\n",
    "#     macros = []\n",
    "    f1s = []\n",
    "    nr_iters = 10\n",
    "    #for train_index, test_index in kf.split(X):\n",
    "    for i in range(nr_iters):    \n",
    "        print('Iter', i)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "        # X_train, X_test = X[train_index], X[test_index]\n",
    "        # y_train, y_test = y[train_index], y[test_index]\n",
    "        model = LogisticRegression(C=1.0, penalty='l1', dual=False, solver='liblinear')\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        n_classes = y_test.shape[1]\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        y_pred_abs = model.predict(X_test)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_abs, average='micro')\n",
    "        print(f1)\n",
    "        f1s.append(f1)\n",
    "\n",
    "#         fpr = dict()\n",
    "#         tpr = dict()\n",
    "#         roc_auc = dict()\n",
    "\n",
    "#         for i in range(n_classes):\n",
    "#             fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "#             roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "#         fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "#         roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#         # First aggregate all false positive rates\n",
    "#         all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "#         # Then interpolate all ROC curves at this points\n",
    "#         mean_tpr = np.zeros_like(all_fpr)\n",
    "#         for i in range(n_classes):\n",
    "#             mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "#         # Finally average it and compute AUC\n",
    "#         mean_tpr /= n_classes\n",
    "\n",
    "#         fpr[\"macro\"] = all_fpr\n",
    "#         tpr[\"macro\"] = mean_tpr\n",
    "#         roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "#         micros.append(roc_auc[\"micro\"])\n",
    "#         macros.append(roc_auc[\"macro\"])\n",
    "        \n",
    "    print('Micro F1', np.mean(f1s))\n",
    "#     print('Macro AUC', np.mean(macros))\n",
    "#     print('Accuracy', np.mean(accs))\n",
    "    \n",
    "#     with open(res_path + \"_w2v_accuracy.txt\", \"w\") as f:\n",
    "#         f.write(str(np.mean(accs)) + \" \" + str(np.std(accs)))\n",
    "    with open(res_path + \"_w2v_micro_F1.txt\", \"w\") as f:\n",
    "        f.write(str(np.mean(f1s)) + \" \" + str(np.std(f1s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "0.22436184505150022\n",
      "Iter 1\n",
      "0.19582433405327573\n",
      "Iter 2\n",
      "0.20752984389348023\n",
      "Iter 3\n",
      "0.19533317296127015\n",
      "Iter 4\n",
      "0.1838630806845966\n",
      "Iter 5\n",
      "0.17525773195876287\n",
      "Iter 6\n",
      "0.18111380145278447\n",
      "Iter 7\n",
      "0.20936130966105604\n",
      "Iter 8\n",
      "0.199443413729128\n",
      "Iter 9\n",
      "0.1633675770483588\n",
      "Micro F1 0.1935456110494213\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/rwalk_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_rw, y_rw, top_classes=top_classes, res_path=res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "0.0\n",
      "Iter 1\n",
      "0.0\n",
      "Iter 2\n",
      "0.0\n",
      "Iter 3\n",
      "0.0\n",
      "Iter 4\n",
      "0.0\n",
      "Iter 5\n",
      "0.0\n",
      "Iter 6\n",
      "0.0\n",
      "Iter 7\n",
      "0.0\n",
      "Iter 8\n",
      "0.0\n",
      "Iter 9\n",
      "0.0\n",
      "Micro F1 0.0\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/nodesketch_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_ns, y_ns, top_classes=top_classes, res_path=res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "0.0\n",
      "Iter 1\n",
      "0.0005932957579353308\n",
      "Iter 2\n",
      "0.0\n",
      "Iter 3\n",
      "0.0\n",
      "Iter 4\n",
      "0.000594000594000594\n",
      "Iter 5\n",
      "0.0017756732761171942\n",
      "Iter 6\n",
      "0.0017974835230677051\n",
      "Iter 7\n",
      "0.0\n",
      "Iter 8\n",
      "0.0\n",
      "Iter 9\n",
      "0.001763150161622098\n",
      "Micro F1 0.0006523603312742922\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/minwise_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_mw, y_mw, top_classes=top_classes, res_path=res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "0.28730226592560926\n",
      "Iter 1\n",
      "0.2997020008514262\n",
      "Iter 2\n",
      "0.29307359307359304\n",
      "Iter 3\n",
      "0.29620090148100453\n",
      "Iter 4\n",
      "0.30383544032569104\n",
      "Iter 5\n",
      "0.28621752531924266\n",
      "Iter 6\n",
      "0.2929491377428509\n",
      "Iter 7\n",
      "0.28709606506924595\n",
      "Iter 8\n",
      "0.2820849759088918\n",
      "Iter 9\n",
      "0.290752688172043\n",
      "Micro F1 0.2919214593869598\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/l1_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_l1, y_l1, top_classes=top_classes, res_path=res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "0.29161234245980006\n",
      "Iter 1\n",
      "0.28997587190173285\n",
      "Iter 2\n",
      "0.2759075907590759\n",
      "Iter 3\n",
      "0.28608695652173916\n",
      "Iter 4\n",
      "0.28720854216604924\n",
      "Iter 5\n",
      "0.2600917431192661\n",
      "Iter 6\n",
      "0.2752374641042633\n",
      "Iter 7\n",
      "0.25986916309496955\n",
      "Iter 8\n",
      "0.2657588403250604\n",
      "Iter 9\n",
      "0.24517019319227232\n",
      "Micro F1 0.27369187076442286\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/l2_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_l2, y_l2, top_classes=top_classes, res_path=res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc(X_rw, y_rw, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc(X_ns, y_ns, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc(X_mw, y_mw, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc(X_l1, y_l1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc(X_l2, y_l2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean balanced accuracy over a number of runs\n",
    "def get_mean_bacc(X, y, nr_iters):\n",
    "    lgb_params = {'objective':'multiclass',\n",
    "                  'metric': 'multi_error',\n",
    "            'boosting_type':'gbdt',\n",
    "            'n_jobs':4,\n",
    "            'max_depth':-1,\n",
    "             'num_class': len(set(y)),\n",
    "            'learning_rate':0.1,\n",
    "            'tree_learner':'serial',\n",
    "            'n_estimators':2000,\n",
    "            'verbose':-1,\n",
    "            'seed': 73,\n",
    "            'feature_fraction':1}\n",
    "    accs = []    \n",
    "    for i in range(nr_iters):\n",
    "        print('Iter', i)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)\n",
    "        clf = lgb.LGBMClassifier( **lgb_params) \n",
    "        X_train_clf, X_test, y_train_clf, y_test =  train_test_split(X_train, y_train)\n",
    "        clf.fit(X_train_clf, y_train_clf, eval_set=[(X_train_clf, y_train_clf), (X_test, y_test)], \n",
    "                    early_stopping_rounds=50, verbose=100)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        acc = bacc(y_pred, y_val)\n",
    "        accs.append(acc)\n",
    "        print('Balanced accuracy score', acc)\n",
    "    mean = 100.0*np.round(np.mean(accs), 3)\n",
    "    std = 100.0*np.round(np.std(accs), 3)\n",
    "    print(\"{}\\% $\\pm$ {}\\%\".format(np.round(mean, 1), np.round(std, 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_mean_bacc(X_rw, y_rw, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_mean_bacc(X_ns, y_ns, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_mean_bacc(X_mw, y_mw, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_mean_bacc(X_l1, y_l1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_mean_bacc(X_l2, y_l2, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
