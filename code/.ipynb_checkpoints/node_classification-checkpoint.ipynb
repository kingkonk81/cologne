{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "import copy\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import balanced_accuracy_score as bacc\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Graphs/HomoSapiens\n"
     ]
    }
   ],
   "source": [
    "graphnames = ['Cora', 'Citeseer', 'Pubmed', 'HomoSapiens', 'Wikipedia', 'BlogCatalog']\n",
    "idx = 4\n",
    "graphname = graphnames[idx]\n",
    "multilabel=False\n",
    "if idx > 2:\n",
    "    multilabel=True\n",
    "emb_size = 50\n",
    "hop = 1\n",
    "data_dir = os.path.expanduser(\"../Graphs/\"+graphname)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwalk_path = data_dir + \"/vectors/vectors_rwalk_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(rwalk_path, \"r\") as read_file:\n",
    "    rwalk_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesketch_path = data_dir + \"/vectors/vectors_nodesketch_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(nodesketch_path, \"r\") as read_file:\n",
    "    ns_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minwise_path = data_dir + \"/vectors/vectors_minwise_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(minwise_path, \"r\") as read_file:\n",
    "    minwise_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_path = data_dir + \"/vectors/vectors_l1_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(l1_path, \"r\") as read_file:\n",
    "    l1_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_path = data_dir + \"/vectors/vectors_l2_all_\" + str(emb_size) + \"_hop_\" + str(hop) + \".json\"\n",
    "with open(l2_path, \"r\") as read_file:\n",
    "    l2_vectors = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3180', 'label=13=17=', '28'],\n",
       " ['1423', 'label=13=17=', '25'],\n",
       " ['2608', 'label=13=17=', '45'],\n",
       " ['1408', 'label=13=17=', '11'],\n",
       " ['2199', 'label=13=17=', '2'],\n",
       " ['3740', 'label=13=17=', '5'],\n",
       " ['3152', 'label=13=17=', 'none'],\n",
       " ['2749', 'label=13=17=', '9'],\n",
       " ['1213', 'label=13=17=', '20'],\n",
       " ['3795', 'label=13=17=', '33'],\n",
       " ['3520', 'label=13=17=', '26'],\n",
       " ['261', 'label=13=17=', '49'],\n",
       " ['3029', 'label=13=17=', '16'],\n",
       " ['738', 'label=13=17=', '14'],\n",
       " ['3437', 'label=13=17=', 'none'],\n",
       " ['648', 'label=13=17=', '2'],\n",
       " ['987', 'label=13=17=', '21'],\n",
       " ['3398', 'label=13=17=', '23'],\n",
       " ['2160', 'label=13=17=', '45'],\n",
       " ['532', 'label=13=17=', '43'],\n",
       " ['2093', 'label=13=17=', '9'],\n",
       " ['1462', 'label=13=17=', '45'],\n",
       " ['1365', 'label=13=17=', '20'],\n",
       " ['250', 'label=13=17=', '16'],\n",
       " ['10', 'label=13=17=', '9'],\n",
       " ['796', 'label=13=17=', 'none'],\n",
       " ['3682', 'label=13=17=', '8'],\n",
       " ['1849', 'label=13=17=', '48'],\n",
       " ['935', 'label=13=17=', '32'],\n",
       " ['2328', 'label=13=17=', '27'],\n",
       " ['1524', 'label=13=17=', '22'],\n",
       " ['1558', 'label=13=17=', '19'],\n",
       " ['2329', 'label=13=17=', '1'],\n",
       " ['351', 'label=13=17=', '19'],\n",
       " ['2334', 'label=13=17=', '28'],\n",
       " ['877', 'label=13=17=', '32'],\n",
       " ['2447', 'label=13=17=', '8'],\n",
       " ['2873', 'label=13=17=', '38'],\n",
       " ['2825', 'label=13=17=', '37'],\n",
       " ['2485', 'label=13=17=', '46'],\n",
       " ['302', 'label=13=17=', '15'],\n",
       " ['2338', 'label=13=17=', '19'],\n",
       " ['840', 'label=13=17=', '33'],\n",
       " ['1446', 'label=13=17=', '10'],\n",
       " ['2153', 'label=13=17=', '5'],\n",
       " ['2608', 'label=13=17=', '45'],\n",
       " ['2338', 'label=13=17=', '19'],\n",
       " ['2763', 'label=13=17=', '25'],\n",
       " ['1442', 'label=13=17=', '18'],\n",
       " ['328', 'label=13=17=', '30']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_vectors['100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "paths = ['graph_nodes.txt', 'labels.txt', 'words_indices.txt']\n",
    "features_path = data_dir + \"/data/\" + paths[x] \n",
    "features = []\n",
    "with open(features_path, \"r\") as features_file:\n",
    "    for f in features_file:\n",
    "        features.append(f.strip())\n",
    "features.append(\"\")\n",
    "features.append(\" \")\n",
    "features.append(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_labels = pd.read_csv(data_dir + '/data/nodes_with_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(nodes_with_labels):\n",
    "    all_labels = set() \n",
    "    for idx, row in nodes_with_labels.iterrows():\n",
    "        node = row['node']\n",
    "        row_labels = [row['label']]\n",
    "        row_labels = row[\"label\"].split(\"=\")\n",
    "        row_labels = row_labels[1:-1]   \n",
    "        if len(row_labels) == 0:\n",
    "            continue\n",
    "        for rl in row_labels:\n",
    "            all_labels.add(rl)\n",
    "    all_labels.add('none')\n",
    "    all_labels.add('nan')\n",
    "    return list(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_labels(nodes_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8', '40', '3']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(vectors, nodes_with_labels, x):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    labels = {}\n",
    "    \n",
    "    for idx, row in nodes_with_labels.iterrows():\n",
    "        node = row['node']\n",
    "        row_labels = [row['label']]\n",
    "        vals = vectors[str(node)]\n",
    "        features = {}\n",
    "        for i, v in enumerate(vals):\n",
    "            features[\"f\"+str(i)] = v[x] \n",
    "        if row['label'][:4] == 'None':\n",
    "            X_test.append(features)\n",
    "        else:\n",
    "            X_train.append(features)\n",
    "        # if multilabel:\n",
    "        row_labels = row[\"label\"].split(\"=\")\n",
    "        row_labels = row_labels[1:-1]   \n",
    "        if len(row_labels) == 0:\n",
    "            continue\n",
    "        for rl in row_labels:\n",
    "            if rl not in labels:\n",
    "                labels[rl] = len(labels)\n",
    "        enc_label = []\n",
    "        for rl in row_labels:\n",
    "            enc_label.append(labels[rl])\n",
    "        if row['label'][:4] == 'None':    \n",
    "            y_test.append(enc_label)\n",
    "        else:\n",
    "            y_train.append(enc_label)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dataset with labels from the trained embeddings\n",
    "def get_X_y(vectors, nodes_with_labels, x, multilabel=False):\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    \n",
    "    for idx, row in nodes_with_labels.iterrows():\n",
    "        node = row['node']\n",
    "        row_labels = [row['label']]\n",
    "        vals = vectors[str(node)]\n",
    "        features = {}\n",
    "        for i, v in enumerate(vals):\n",
    "            features[\"f\"+str(i)] = v[x] \n",
    "        X.append(features)\n",
    "        if multilabel:\n",
    "            row_labels = row[\"label\"].split(\"=\")\n",
    "            row_labels = row_labels[1:-1]   \n",
    "        if len(row_labels) == 0:\n",
    "            continue\n",
    "        for rl in row_labels:\n",
    "            if rl not in labels:\n",
    "                labels[rl] = len(labels)\n",
    "        enc_label = []\n",
    "        for rl in row_labels:\n",
    "            enc_label.append(labels[rl])\n",
    "        y.append(enc_label)\n",
    "    X = pd.DataFrame(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multilabel:\n",
    "    X_rw_train, X_rw_test, y_rw_train, y_rw_test = get_train_test(rwalk_vectors, nodes_with_labels, x=x) \n",
    "else:\n",
    "    X_rw, y_rw = get_X_y(rwalk_vectors, nodes_with_labels, x=x, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multilabel:\n",
    "    X_ns_train, X_ns_test, y_ns_train, y_ns_test = get_train_test(ns_vectors, nodes_with_labels, x=x) \n",
    "else:\n",
    "    X_ns, y_ns = get_X_y(ns_vectors, nodes_with_labels, x=x, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multilabel:\n",
    "    X_mw_train, X_mw_test, y_mw_train, y_mw_test = get_train_test(minwise_vectors, nodes_with_labels, x=x) \n",
    "else:\n",
    "    X_mw, y_mw = get_X_y(minwise_vectors, nodes_with_labels, x=x, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multilabel:\n",
    "    X_l1_train, X_l1_test, y_l1_train, y_l1_test = get_train_test(l1_vectors, nodes_with_labels, x=x) \n",
    "else:\n",
    "    X_l1, y_l1 = get_X_y(l1_vectors, nodes_with_labels, x=x, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multilabel:\n",
    "    X_l2_train, X_l2_test, y_l2_train, y_l2_test = get_train_test(l2_vectors, nodes_with_labels, x=x) \n",
    "else:\n",
    "    X_l2, y_l2 = get_X_y(l2_vectors, nodes_with_labels, x=x, multilabel=multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3079, 50), (811, 50))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_l1_train.shape, X_l1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_prec_recall(y_true, y_pred):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "    return tp/(tp+fp), tp/(tp+fn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_distribution(y):\n",
    "    counts = {}\n",
    "    for labels_i in y:\n",
    "        for l_i in labels_i:\n",
    "            counts.setdefault(l_i, 0)\n",
    "            counts[l_i] += 1\n",
    "    \n",
    "    top_counts = sorted([(cnt, lbl) for lbl, cnt in counts.items()], reverse=True)\n",
    "    plt.bar([i for i in range(len(top_counts))], [c for c, _ in top_counts], alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, top=10):\n",
    "    \n",
    "    counts = {}\n",
    "    for labels_i in y:\n",
    "        for l_i in labels_i:\n",
    "            counts.setdefault(l_i, 0)\n",
    "            counts[l_i] += 1\n",
    "    \n",
    "    top_counts = sorted([(cnt, lbl) for lbl, cnt in counts.items()], reverse=True)[:top]\n",
    "    labels = {cnt_lbl[1]: i for i,cnt_lbl in enumerate(top_counts)}\n",
    "        \n",
    "    top = min(top, len(counts)-1)\n",
    "    \n",
    "    encoded = np.zeros((len(y), top+1))\n",
    "    for i, labels_i in enumerate(y):\n",
    "        for l_i in labels_i:\n",
    "            if l_i in labels:\n",
    "                encoded[i, labels[l_i]] = 1\n",
    "            else:\n",
    "                encoded[i, top] = 1\n",
    "            \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_classification(X_train, X_test, y_train, y_test, features, top_classes, res_path):\n",
    "    # mlb = MultiLabelBinarizer()\n",
    "    y = y_train + y_test\n",
    "    y = one_hot(y, top_classes) # mlb.fit_transform(y)\n",
    "    y_train = y[:len(y_train)]\n",
    "    y_test = y[len(y_train):]\n",
    "    \n",
    "#     lgb_params = {'objective':'binary',\n",
    "#                   'metric': 'auc',\n",
    "#             'boosting_type':'gbdt',\n",
    "#             'n_jobs':4,\n",
    "#             'max_depth':-1,\n",
    "#              # 'num_class': len(labels),\n",
    "#             'learning_rate':0.1,\n",
    "#             'tree_learner':'serial',\n",
    "#             'n_estimators':2000,\n",
    "#             'verbose':-1,\n",
    "#             'seed': 73,\n",
    "#             'feature_fraction':1}\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(features)\n",
    "    \n",
    "    X_train = copy.deepcopy(X_train)\n",
    "    for c in X_train.columns: \n",
    "        X_train.loc[:, c] = label_encoder.transform([str(x) for x in X_train[c]])\n",
    "        \n",
    "    X_test = copy.deepcopy(X_test)\n",
    "    for c in X_test.columns: \n",
    "        X_test.loc[:, c] = label_encoder.transform([str(x) for x in X_test[c]])\n",
    "    \n",
    "    # X.to_csv(\"/home/koki2/Desktop/X.csv\", index=False)\n",
    "    f1_micros = []\n",
    "    f1_macros = []\n",
    "    nr_iters = 10\n",
    "    #for train_index, test_index in kf.split(X):\n",
    "    for i in range(nr_iters):    \n",
    "        print('Iter', i)\n",
    "        X_tr, _, y_tr, _ = train_test_split(X_train, y_train, train_size=0.9)\n",
    "        # X_train, X_test = X[train_index], X[test_index]\n",
    "        # y_train, y_test = y[train_index], y[test_index]\n",
    "        # model = lgb.LGBMClassifier( **lgb_params) \n",
    "        \n",
    "        # model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "        model = tree.DecisionTreeClassifier() \n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # n_classes = y_test.shape[1]\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        y_pred_abs = model.predict(X_test)\n",
    "        \n",
    "        f1_micro = f1_score(y_test, y_pred_abs, average='micro')\n",
    "        f1_macro = f1_score(y_test, y_pred_abs, average='macro')\n",
    "        #bf1 = f1_score(y_test.ravel(), y_pred_abs.ravel(), average='binary')\n",
    "        print(\"F1\", f1_micro, f1_macro)\n",
    "        f1_micros.append(f1_micro)\n",
    "        f1_macros.append(f1_macro)\n",
    "        \n",
    "    print('Micro F1', np.mean(f1_micros))\n",
    "    print('Macro F1', np.mean(f1_macros))\n",
    "#     print('Macro AUC', np.mean(macros))\n",
    "#     print('Accuracy', np.mean(accs))\n",
    "    \n",
    "    with open(res_path + \"_emb_micro_F1.txt\", \"w\") as f:\n",
    "        f.write(str(np.mean(f1_micros)) + \" \" + str(np.std(f1_micros)))\n",
    "        \n",
    "    with open(res_path + \"_emb_macro_F1.txt\", \"w\") as f:\n",
    "        f.write(str(np.mean(f1_macros)) + \" \" + str(np.std(f1_macros)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_label_distribution(y_l1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "F1 0.04573804573804574 0.03824133991796889\n",
      "Iter 1\n",
      "F1 0.055522027761013885 0.046021061589781136\n",
      "Iter 2\n",
      "F1 0.049861495844875356 0.040843871756636625\n",
      "Iter 3\n",
      "F1 0.04887983706720978 0.039564286360734044\n",
      "Iter 4\n",
      "F1 0.048243001786777845 0.04186058639900628\n",
      "Iter 5\n",
      "F1 0.042527339003645206 0.038639060548416676\n",
      "Iter 6\n",
      "F1 0.04780400358530027 0.03918789947711135\n",
      "Iter 7\n",
      "F1 0.04673748103186646 0.03689190478191622\n",
      "Iter 8\n",
      "F1 0.04074186682882335 0.03462216056148192\n",
      "Iter 9\n",
      "F1 0.046566460359563806 0.042885257296004876\n",
      "Micro F1 0.04726215590071217\n",
      "Macro F1 0.03987574286890581\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/rwalk_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_rw_train, X_rw_test, y_rw_train, y_rw_test, features, top_classes, res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "F1 0.060553633217993084 0.05671029166182683\n",
      "Iter 1\n",
      "F1 0.04929577464788732 0.04673191352948567\n",
      "Iter 2\n",
      "F1 0.04817204301075268 0.05194938515472002\n",
      "Iter 3\n",
      "F1 0.04727116458960035 0.04414825056475216\n",
      "Iter 4\n",
      "F1 0.057667103538663174 0.051230157473777786\n",
      "Iter 5\n",
      "F1 0.055045871559633024 0.05427695643511348\n",
      "Iter 6\n",
      "F1 0.048484848484848485 0.05221786628968845\n",
      "Iter 7\n",
      "F1 0.05352363960749331 0.050504816124620024\n",
      "Iter 8\n",
      "F1 0.05056669572798605 0.051452193257549766\n",
      "Iter 9\n",
      "F1 0.04839419269687638 0.04629700670066432\n",
      "Micro F1 0.05189749670817338\n",
      "Macro F1 0.05055188371921985\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/nodesketch_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_ns_train, X_ns_test, y_ns_train, y_ns_test, features, top_classes, res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "F1 0.0 0.0\n",
      "Iter 1\n",
      "F1 0.0 0.0\n",
      "Iter 2\n",
      "F1 0.0 0.0\n",
      "Iter 3\n",
      "F1 0.0 0.0\n",
      "Iter 4\n",
      "F1 0.0 0.0\n",
      "Iter 5\n",
      "F1 0.0 0.0\n",
      "Iter 6\n",
      "F1 0.0 0.0\n",
      "Iter 7\n",
      "F1 0.0 0.0\n",
      "Iter 8\n",
      "F1 0.0 0.0\n",
      "Iter 9\n",
      "F1 0.0 0.0\n",
      "Micro F1 0.0\n",
      "Macro F1 0.0\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/minwise_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_mw_train, X_mw_test, y_mw_train, y_mw_test, features, top_classes, res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "F1 0.014102564102564101 0.011784709706776975\n",
      "Iter 1\n",
      "F1 0.012944983818770227 0.01209254437281756\n",
      "Iter 2\n",
      "F1 0.019430051813471502 0.01592628356443223\n",
      "Iter 3\n",
      "F1 0.01944264419961115 0.017678817064964023\n",
      "Iter 4\n",
      "F1 0.01935483870967742 0.021294534883435978\n",
      "Iter 5\n",
      "F1 0.02557544757033248 0.02167531782609318\n",
      "Iter 6\n",
      "F1 0.02209226770630279 0.01746763598349881\n",
      "Iter 7\n",
      "F1 0.017960230917254648 0.016028389613199488\n",
      "Iter 8\n",
      "F1 0.014211886304909558 0.012245711595282847\n",
      "Iter 9\n",
      "F1 0.019659239842726082 0.016631735248638452\n",
      "Micro F1 0.018477415498561994\n",
      "Macro F1 0.016282567985913952\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/l1_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_l1_train, X_l1_test, y_l1_train, y_l1_test, features, top_classes, res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "F1 0.04530120481927711 0.03904554595630004\n",
      "Iter 1\n",
      "F1 0.03655603655603656 0.033051762980032005\n",
      "Iter 2\n",
      "F1 0.04105011933174224 0.034291329787808446\n",
      "Iter 3\n",
      "F1 0.038517091959557055 0.03063906556022425\n",
      "Iter 4\n",
      "F1 0.04950023798191338 0.042699064593008255\n",
      "Iter 5\n",
      "F1 0.0410958904109589 0.03686973231916126\n",
      "Iter 6\n",
      "F1 0.04787493893502687 0.04097780915847176\n",
      "Iter 7\n",
      "F1 0.04596577017114914 0.03884955085276845\n",
      "Iter 8\n",
      "F1 0.04395604395604395 0.03874259739223265\n",
      "Iter 9\n",
      "F1 0.03819784524975514 0.036118770109837106\n",
      "Micro F1 0.04280151793714604\n",
      "Macro F1 0.03712852287098443\n"
     ]
    }
   ],
   "source": [
    "res_path = data_dir + \"/results/l2_\" + str(emb_size) + \"_hop_\" + str(hop) \n",
    "multilabel_classification(X_l2_train, X_l2_test, y_l2_train, y_l2_test, features, top_classes, res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
